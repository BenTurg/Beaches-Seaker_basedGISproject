name: Run JavaScript scraping files every 5 minutes to update beaches dynamic data

on:
  schedule:
    - cron: '*/5 * * * *'

jobs:
  run-scripts:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Use Node.js
        uses: actions/setup-node@v2
        with:
          node-version: '16.x'

      - name: Install dependencies
        run: npm install

      - name: Install Puppeteer
        run: npm install puppeteer
        
      - name: Run scripts
        run: |
          node export_html/qgis2web_2023_05_11-15_30_42_882962/scrapping/scrapping/scrapping_scripts/bat_yam_scrape.js
          node export_html/qgis2web_2023_05_11-15_30_42_882962/scrapping/scrapping/scrapping_scripts/herzelia_scrape.js
          node export_html/qgis2web_2023_05_11-15_30_42_882962/scrapping/scrapping/scrapping_scripts/natanya_scrape.js
          node export_html/qgis2web_2023_05_11-15_30_42_882962/scrapping/scrapping/scrapping_scripts/rishon_letzion_scrape.js
          node export_html/qgis2web_2023_05_11-15_30_42_882962/scrapping/scrapping/scrapping_scripts/tel_aviv_scrape.js
          
      - name: Commit changes
        env:
          GITHUB_TOKEN: ${{ secrets.OUR_GIS_SECRET }}
        run: |
          git config --global user.email "GISbeaches2023@gmail.com"
          git config --global user.name "LiorBenAmit"
          git add .
          git commit -m "GitHub Actions: automatically Update files"
          git push
